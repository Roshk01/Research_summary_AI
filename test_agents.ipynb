{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9391ade",
   "metadata": {},
   "source": [
    "# Check for Search agent API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5023550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.search_agent import search_arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a2358b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1] An Exploration of Post-Editing Effectiveness in Text Summarization\n",
      "Published: 2022-06-13T18:00:02Z\n",
      "Link: http://arxiv.org/abs/2206.06383v1\n",
      "Summary: Automatic summarization methods are efficient but can suffer from low\n",
      "quality. In comparison, manual summarization is expensive but produces higher\n",
      "quality. Can humans and AI collaborate to improve summarization performance? In\n",
      "similar text generation tasks (e.g., machine translation), human-AI\n",
      "coll\n",
      "\n",
      "[2] A Brief Survey of Associations Between Meta-Learning and General AI\n",
      "Published: 2021-01-12T03:57:16Z\n",
      "Link: http://arxiv.org/abs/2101.04283v1\n",
      "Summary: This paper briefly reviews the history of meta-learning and describes its\n",
      "contribution to general AI. Meta-learning improves model generalization\n",
      "capacity and devises general algorithms applicable to both in-distribution and\n",
      "out-of-distribution tasks potentially. General AI replaces task-specific mo\n",
      "\n",
      "[3] The Current State of Summarization\n",
      "Published: 2023-05-08T17:00:49Z\n",
      "Link: http://arxiv.org/abs/2305.04853v2\n",
      "Summary: With the explosive growth of textual information, summarization systems have\n",
      "become increasingly important. This work aims to concisely indicate the current\n",
      "state of the art in abstractive text summarization. As part of this, we outline\n",
      "the current paradigm shifts towards pre-trained encoder-decoder\n",
      "\n",
      "[4] Mapping the Design Space of Human-AI Interaction in Text Summarization\n",
      "Published: 2022-06-29T19:03:25Z\n",
      "Link: http://arxiv.org/abs/2206.14863v1\n",
      "Summary: Automatic text summarization systems commonly involve humans for preparing\n",
      "data or evaluating model performance, yet, there lacks a systematic\n",
      "understanding of humans' roles, experience, and needs when interacting with or\n",
      "being assisted by AI. From a human-centered perspective, we map the design\n",
      "opp\n"
     ]
    }
   ],
   "source": [
    "# Example usage of the search_arxiv function\n",
    "papers = search_arxiv(\"AI summarization\", max_results=4)\n",
    "for i, paper in enumerate(papers, 1):\n",
    "    print(f\"\\n[{i}] {paper['title']}\")\n",
    "    print(f\"Published: {paper['Published']}\")\n",
    "    print(f\"Link: {paper['link']}\")\n",
    "    print(f\"Summary: {paper['summary'][:300]}\")  # Display first 300 characters of summary\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af44e36f",
   "metadata": {},
   "source": [
    "# Test the PDF upload and text extraction (preprocess_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0877c140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.preprocess_agent import extract_text_from_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "becb8a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guru Gobind Singh Indraprastha University (GGSIPU) \n",
      "1, December - 2023, pages: 1-6 \n",
      " \n",
      " \n",
      "1 \n",
      " \n",
      "The Future of Blood Donation Using Web-based ML Approach \n",
      "Er. Roshani Kumari \n",
      "Department of Computer Science and Engineering, GGSIP University, Delhi, India \n",
      " \n",
      "Abstract: The aim of this research is the study of a machine learning algorithm with the help of Web \n",
      "development for recommending the nearest blood bank. The availability and efficient allocation of blood units \n",
      "are critical factors in ensuring timely and effective healthcare delivery. To address the challenges associated \n",
      "with blood donation and allocation processes, we present a novel approach that leverages web development and \n",
      "machine learning (ML) techniques to create a blood bank recommendation system. This paper explores the \n",
      "design, implementation, and evaluation of such a system to improve the accessibility and effectiveness of blood \n",
      "donation services. \n",
      "In addition to the technical aspects, we consider the usability and adopti\n"
     ]
    }
   ],
   "source": [
    "text = extract_text_from_pdf(\"demo_dataset/example.pdf\")\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed268ce",
   "metadata": {},
   "source": [
    "# Test Classification agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10fb53d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified Topic: Natural Language Processing with score 0.08\n",
      "Predicted Topic: Reinforcement Learning (Score: 0.36)\n"
     ]
    }
   ],
   "source": [
    "from agents.classification import classify_paper_to_topic\n",
    "\n",
    "paper_text1 = \"\"\"This paper discusses transformer-based models for summarization tasks \n",
    "and fine-tuning BERT variants. The models are evaluated on multiple datasets \n",
    "in the context of language understanding and generation.\"\"\"\n",
    "\n",
    "topics1 = [\"Medical AI\", \"Natural Language Processing\", \"Reinforcement Learning\"]\n",
    "\n",
    "topic1, score1 = classify_paper_to_topic(paper_text1, topics1)\n",
    "print(f\"Classified Topic: {topic1} with score {score1:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "paper_text2 = \"\"\"\n",
    "We introduce a new multi-agent reinforcement learning algorithm that improves\n",
    "cooperation and reward sharing in competitive environments. Our approach builds on\n",
    "Q-learning and achieves better generalization in complex tasks.\n",
    "\"\"\"\n",
    "\n",
    "topics2 = [\"Reinforcement Learning\", \"Vision Transformers\", \"Edge Computing\"]\n",
    "\n",
    "topic2, score2 = classify_paper_to_topic(paper_text2, topics2)\n",
    "print(f\"Predicted Topic: {topic2} (Score: {score2:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13778b2a",
   "metadata": {},
   "source": [
    "# Test summary_agent LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2518e0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aman\\AppData\\Local\\Temp\\ipykernel_12512\\3545385776.py\", line 1, in <module>\n",
      "    from agents.summerize_agent import summarize_text\n",
      "  File \"c:\\Users\\Aman\\machine_learning_projects\\Research_paper_summary_AI\\agents\\summerize_agent.py\", line 3, in <module>\n",
      "    summerizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
      "  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\transformers\\pipelines\\__init__.py\", line 779, in pipeline\n",
      "    framework, model = infer_framework_load_model(\n",
      "  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\transformers\\pipelines\\base.py\", line 262, in infer_framework_load_model\n",
      "    model = model_class.from_pretrained(model, **kwargs)\n",
      "  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 471, in from_pretrained\n",
      "    return model_class.from_pretrained(\n",
      "  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\transformers\\modeling_utils.py\", line 2560, in from_pretrained\n",
      "    state_dict = load_state_dict(resolved_archive_file)\n",
      "  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\transformers\\modeling_utils.py\", line 442, in load_state_dict\n",
      "    return torch.load(checkpoint_file, map_location=\"cpu\")\n",
      "  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\torch\\serialization.py\", line 815, in load\n",
      "    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\n",
      "  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\torch\\serialization.py\", line 1043, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\torch\\serialization.py\", line 975, in persistent_load\n",
      "    obj = cast(Storage, torch.UntypedStorage(nbytes))\n",
      "c:\\Users\\Aman\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\torch\\serialization.py:975: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  obj = cast(Storage, torch.UntypedStorage(nbytes))\n"
     ]
    }
   ],
   "source": [
    "from agents.summerize_agent import summarize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1c2603c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring args : (1000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 142, but you input_length is only 59. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=29)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "  Transfer learning significantly improves summarization performance on low-resource datasets . Transformer-based models have recently become the dominant architecture in NLP tasks . This paper explores different fine-tuning strategies on BERT and RoBERTa for summarization .\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Transformer-based models have recently become the dominant architecture in NLP tasks.\n",
    "This paper explores different fine-tuning strategies on BERT and RoBERTa for summarization.\n",
    "We show that transfer learning significantly improves summarization performance on low-resource datasets.\n",
    "\"\"\"\n",
    "\n",
    "summary = summarize_text(text)\n",
    "print(\"Summary:\\n\", summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907e95e5",
   "metadata": {},
   "source": [
    "# Test synthetic summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d14647ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.synthesis_agent import synthesise_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2586e0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_by_topic = {\n",
    "    \"Natural Language Processing\": [\n",
    "        \"Transformer-based models like BERT and RoBERTa have revolutionized NLP tasks by using self-attention mechanisms and large-scale pretraining.\",\n",
    "        \"Recent studies have focused on efficient fine-tuning techniques such as LoRA and PEFT to reduce computational costs while maintaining performance.\",\n",
    "        \"Evaluation benchmarks like SuperGLUE and SummEval are used to compare model accuracy, robustness, and generalization across multiple NLP tasks.\",\n",
    "        \"Cross-lingual transfer and zero-shot learning have gained momentum, enabling models trained on one language to perform tasks in others without retraining.\",\n",
    "        \"However, current summarization systems often struggle with factual consistency and tend to hallucinate content in long-document settings.\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6235dfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 150, but you input_length is only 142. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=71)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: Natural Language Processing\n",
      "Summary:  Transformer-based models like BERT and RoBERTa have revolutionized NLP tasks by using self-attention mechanisms and large-scale pretraining . Recent studies have focused on efficient fine-tuning techniques such as LoRA and PEFT to reduce computational costs while maintaining performance .\n"
     ]
    }
   ],
   "source": [
    "output = synthesise_summary(summaries_by_topic)\n",
    "for summary in output:\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc4dcb8",
   "metadata": {},
   "source": [
    "# Test audio agent offline service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8abd8a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyttsx3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio_agent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m text_to_audio_light\n",
      "File \u001b[1;32mc:\\Users\\Aman\\machine_learning_projects\\Research_paper_summary_AI\\agents\\audio_agent.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyttsx3\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtext_to_audio_light\u001b[39m(text, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary_audio.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_audio\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyttsx3'"
     ]
    }
   ],
   "source": [
    "from agents.audio_agent import text_to_audio_light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22438bde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summarizer_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
